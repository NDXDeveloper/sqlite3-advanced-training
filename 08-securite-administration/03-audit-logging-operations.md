üîù Retour au [Sommaire](/SOMMAIRE.md)

# 8.3 Audit et logging des op√©rations

## Introduction √† l'audit et au logging

L'audit et le logging sont essentiels pour maintenir la s√©curit√© et la tra√ßabilit√© de votre base de donn√©es SQLite. Contrairement aux syst√®mes de bases de donn√©es d'entreprise qui ont des syst√®mes d'audit int√©gr√©s, SQLite n√©cessite que vous impl√©mentiez votre propre syst√®me de suivi des op√©rations.

### Qu'est-ce que l'audit et le logging ?

**Audit** : Enregistrement syst√©matique des actions effectu√©es sur la base de donn√©es pour des raisons de s√©curit√©, de conformit√© et de tra√ßabilit√©.

**Logging** : Enregistrement d√©taill√© des √©v√©nements et op√©rations pour le d√©bogage, le monitoring et l'analyse des performances.

### Pourquoi impl√©menter l'audit dans SQLite ?

**Raisons de s√©curit√© :**
- D√©tecter les acc√®s non autoris√©s
- Identifier les tentatives d'intrusion
- Tracer les modifications de donn√©es sensibles
- Prouver la conformit√© r√©glementaire

**Raisons op√©rationnelles :**
- D√©boguer les probl√®mes de donn√©es
- Analyser les patterns d'utilisation
- Optimiser les performances
- Restaurer des donn√©es modifi√©es par erreur

**Sc√©narios concrets :**
```
üè• Application m√©dicale : Tracer qui a consult√© quel dossier patient
üí∞ Application financi√®re : Enregistrer toutes les transactions
üìä Application RH : Auditer les modifications de salaires
üîê Syst√®me d'administration : Logger tous les changements de permissions
```

## Conception d'un syst√®me d'audit

### Structure de base pour l'audit

Commen√ßons par cr√©er les tables n√©cessaires pour un syst√®me d'audit complet :

```sql
-- Table principale d'audit
CREATE TABLE audit_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    utilisateur_id INTEGER,
    nom_utilisateur TEXT,
    action TEXT NOT NULL,                    -- SELECT, INSERT, UPDATE, DELETE
    table_cible TEXT,                        -- Table concern√©e
    enregistrement_id INTEGER,               -- ID de l'enregistrement modifi√©
    anciennes_valeurs TEXT,                  -- JSON des anciennes valeurs
    nouvelles_valeurs TEXT,                  -- JSON des nouvelles valeurs
    adresse_ip TEXT,
    user_agent TEXT,
    session_id TEXT,
    duree_ms INTEGER,                        -- Dur√©e de l'op√©ration en millisecondes
    statut TEXT DEFAULT 'SUCCESS',           -- SUCCESS, ERROR, WARNING
    message_erreur TEXT,
    FOREIGN KEY (utilisateur_id) REFERENCES utilisateurs(id)
);

-- Table pour les √©v√©nements de s√©curit√© sp√©cifiques
CREATE TABLE audit_securite (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    type_evenement TEXT NOT NULL,            -- LOGIN, LOGOUT, FAILED_LOGIN, PERMISSION_DENIED
    utilisateur_id INTEGER,
    nom_utilisateur TEXT,
    adresse_ip TEXT,
    details TEXT,                            -- JSON avec d√©tails sp√©cifiques
    niveau_gravite TEXT DEFAULT 'INFO',      -- INFO, WARNING, CRITICAL
    FOREIGN KEY (utilisateur_id) REFERENCES utilisateurs(id)
);

-- Table pour l'audit des changements de sch√©ma
CREATE TABLE audit_schema (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    utilisateur_id INTEGER,
    type_operation TEXT,                     -- CREATE_TABLE, ALTER_TABLE, DROP_TABLE, etc.
    nom_objet TEXT,                         -- Nom de la table/index/trigger
    definition_sql TEXT,                    -- SQL complet de la modification
    FOREIGN KEY (utilisateur_id) REFERENCES utilisateurs(id)
);

-- Index pour am√©liorer les performances des requ√™tes d'audit
CREATE INDEX idx_audit_timestamp ON audit_log(timestamp);
CREATE INDEX idx_audit_utilisateur ON audit_log(utilisateur_id);
CREATE INDEX idx_audit_table ON audit_log(table_cible);
CREATE INDEX idx_audit_securite_timestamp ON audit_securite(timestamp);
CREATE INDEX idx_audit_securite_type ON audit_securite(type_evenement);
```

### Classe Python pour la gestion de l'audit

```python
import json
import time
import sqlite3
from datetime import datetime
from typing import Optional, Dict, Any

class AuditManager:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base
        self.utilisateur_actuel = None
        self.session_id = None
        self.adresse_ip = None
        self._creer_tables_audit()

    def _creer_tables_audit(self):
        """Cr√©e les tables d'audit si elles n'existent pas"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # Ex√©cuter les CREATE TABLE (voir ci-dessus)
        # ... (code SQL des tables)

        conn.commit()
        conn.close()

    def definir_contexte(self, utilisateur_id: int, nom_utilisateur: str,
                        session_id: str = None, adresse_ip: str = None):
        """D√©finit le contexte pour les op√©rations d'audit"""
        self.utilisateur_actuel = {
            'id': utilisateur_id,
            'nom': nom_utilisateur
        }
        self.session_id = session_id
        self.adresse_ip = adresse_ip

    def enregistrer_operation(self, action: str, table_cible: str = None,
                            enregistrement_id: int = None,
                            anciennes_valeurs: Dict = None,
                            nouvelles_valeurs: Dict = None,
                            duree_ms: int = None,
                            statut: str = 'SUCCESS',
                            message_erreur: str = None):
        """Enregistre une op√©ration dans le log d'audit"""

        try:
            conn = sqlite3.connect(self.chemin_base)
            cursor = conn.cursor()

            cursor.execute("""
                INSERT INTO audit_log (
                    utilisateur_id, nom_utilisateur, action, table_cible,
                    enregistrement_id, anciennes_valeurs, nouvelles_valeurs,
                    adresse_ip, session_id, duree_ms, statut, message_erreur
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                self.utilisateur_actuel['id'] if self.utilisateur_actuel else None,
                self.utilisateur_actuel['nom'] if self.utilisateur_actuel else 'SYSTEM',
                action,
                table_cible,
                enregistrement_id,
                json.dumps(anciennes_valeurs) if anciennes_valeurs else None,
                json.dumps(nouvelles_valeurs) if nouvelles_valeurs else None,
                self.adresse_ip,
                self.session_id,
                duree_ms,
                statut,
                message_erreur
            ))

            conn.commit()
            conn.close()

        except Exception as e:
            # En cas d'erreur d'audit, ne pas faire planter l'application
            print(f"Erreur audit: {e}")

    def enregistrer_evenement_securite(self, type_evenement: str,
                                     details: Dict = None,
                                     niveau_gravite: str = 'INFO'):
        """Enregistre un √©v√©nement de s√©curit√©"""

        try:
            conn = sqlite3.connect(self.chemin_base)
            cursor = conn.cursor()

            cursor.execute("""
                INSERT INTO audit_securite (
                    type_evenement, utilisateur_id, nom_utilisateur,
                    adresse_ip, details, niveau_gravite
                ) VALUES (?, ?, ?, ?, ?, ?)
            """, (
                type_evenement,
                self.utilisateur_actuel['id'] if self.utilisateur_actuel else None,
                self.utilisateur_actuel['nom'] if self.utilisateur_actuel else 'ANONYMOUS',
                self.adresse_ip,
                json.dumps(details) if details else None,
                niveau_gravite
            ))

            conn.commit()
            conn.close()

        except Exception as e:
            print(f"Erreur audit s√©curit√©: {e}")

    def lire_audit(self, limite: int = 100, filtre_utilisateur: str = None,
                   filtre_action: str = None, date_debut: str = None,
                   date_fin: str = None):
        """Lit les entr√©es d'audit avec filtres"""

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # Construire la requ√™te avec les filtres
        where_clauses = []
        params = []

        if filtre_utilisateur:
            where_clauses.append("nom_utilisateur = ?")
            params.append(filtre_utilisateur)

        if filtre_action:
            where_clauses.append("action = ?")
            params.append(filtre_action)

        if date_debut:
            where_clauses.append("timestamp >= ?")
            params.append(date_debut)

        if date_fin:
            where_clauses.append("timestamp <= ?")
            params.append(date_fin)

        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)

        params.append(limite)

        cursor.execute(f"""
            SELECT id, timestamp, nom_utilisateur, action, table_cible,
                   enregistrement_id, anciennes_valeurs, nouvelles_valeurs,
                   adresse_ip, duree_ms, statut, message_erreur
            FROM audit_log
            {where_clause}
            ORDER BY timestamp DESC
            LIMIT ?
        """, params)

        resultats = cursor.fetchall()
        conn.close()

        return resultats

# Exemple d'utilisation basique
audit = AuditManager('ma_base.db')

# D√©finir le contexte utilisateur
audit.definir_contexte(
    utilisateur_id=1,
    nom_utilisateur='alice',
    session_id='sess_123',
    adresse_ip='192.168.1.100'
)

# Enregistrer une op√©ration
audit.enregistrer_operation(
    action='INSERT',
    table_cible='clients',
    enregistrement_id=42,
    nouvelles_valeurs={'nom': 'Nouveau Client', 'email': 'client@email.com'},
    duree_ms=15
)

# Enregistrer un √©v√©nement de s√©curit√©
audit.enregistrer_evenement_securite(
    type_evenement='LOGIN',
    details={'methode': 'password', 'succes': True},
    niveau_gravite='INFO'
)
```

## Audit automatique avec des triggers

### Utilisation des triggers SQLite pour l'audit automatique

Les triggers permettent d'automatiser l'audit sans modifier le code applicatif :

```sql
-- Trigger pour auditer les insertions dans la table clients
CREATE TRIGGER audit_clients_insert
AFTER INSERT ON clients
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        nom_utilisateur, action, table_cible, enregistrement_id,
        nouvelles_valeurs, timestamp
    ) VALUES (
        COALESCE((SELECT nom_utilisateur FROM session_actuelle LIMIT 1), 'SYSTEM'),
        'INSERT',
        'clients',
        NEW.id,
        json_object(
            'nom', NEW.nom,
            'email', NEW.email,
            'telephone', NEW.telephone,
            'date_creation', NEW.date_creation
        ),
        CURRENT_TIMESTAMP
    );
END;

-- Trigger pour auditer les modifications dans la table clients
CREATE TRIGGER audit_clients_update
AFTER UPDATE ON clients
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        nom_utilisateur, action, table_cible, enregistrement_id,
        anciennes_valeurs, nouvelles_valeurs, timestamp
    ) VALUES (
        COALESCE((SELECT nom_utilisateur FROM session_actuelle LIMIT 1), 'SYSTEM'),
        'UPDATE',
        'clients',
        NEW.id,
        json_object(
            'nom', OLD.nom,
            'email', OLD.email,
            'telephone', OLD.telephone
        ),
        json_object(
            'nom', NEW.nom,
            'email', NEW.email,
            'telephone', NEW.telephone
        ),
        CURRENT_TIMESTAMP
    );
END;

-- Trigger pour auditer les suppressions dans la table clients
CREATE TRIGGER audit_clients_delete
AFTER DELETE ON clients
FOR EACH ROW
BEGIN
    INSERT INTO audit_log (
        nom_utilisateur, action, table_cible, enregistrement_id,
        anciennes_valeurs, timestamp
    ) VALUES (
        COALESCE((SELECT nom_utilisateur FROM session_actuelle LIMIT 1), 'SYSTEM'),
        'DELETE',
        'clients',
        OLD.id,
        json_object(
            'nom', OLD.nom,
            'email', OLD.email,
            'telephone', OLD.telephone
        ),
        CURRENT_TIMESTAMP
    );
END;

-- Table temporaire pour stocker l'utilisateur de la session courante
CREATE TABLE IF NOT EXISTS session_actuelle (
    nom_utilisateur TEXT
);
```

### Classe Python pour g√©rer l'audit automatique

```python
class AuditAutomatique:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base
        self.audit_manager = AuditManager(chemin_base)

    def definir_utilisateur_session(self, nom_utilisateur: str):
        """D√©finit l'utilisateur pour les triggers d'audit"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # Vider et d√©finir l'utilisateur actuel
        cursor.execute("DELETE FROM session_actuelle")
        cursor.execute("INSERT INTO session_actuelle (nom_utilisateur) VALUES (?)",
                      (nom_utilisateur,))

        conn.commit()
        conn.close()

    def creer_triggers_audit_table(self, nom_table: str, colonnes_a_auditer: list):
        """Cr√©e automatiquement les triggers d'audit pour une table"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # Construire la liste des colonnes pour JSON
        colonnes_json = ", ".join([f"'{col}', NEW.{col}" for col in colonnes_a_auditer])
        colonnes_json_old = ", ".join([f"'{col}', OLD.{col}" for col in colonnes_a_auditer])

        # Trigger INSERT
        trigger_insert = f"""
        CREATE TRIGGER IF NOT EXISTS audit_{nom_table}_insert
        AFTER INSERT ON {nom_table}
        FOR EACH ROW
        BEGIN
            INSERT INTO audit_log (
                nom_utilisateur, action, table_cible, enregistrement_id,
                nouvelles_valeurs, timestamp
            ) VALUES (
                COALESCE((SELECT nom_utilisateur FROM session_actuelle LIMIT 1), 'SYSTEM'),
                'INSERT',
                '{nom_table}',
                NEW.id,
                json_object({colonnes_json}),
                CURRENT_TIMESTAMP
            );
        END;
        """

        # Trigger UPDATE
        trigger_update = f"""
        CREATE TRIGGER IF NOT EXISTS audit_{nom_table}_update
        AFTER UPDATE ON {nom_table}
        FOR EACH ROW
        BEGIN
            INSERT INTO audit_log (
                nom_utilisateur, action, table_cible, enregistrement_id,
                anciennes_valeurs, nouvelles_valeurs, timestamp
            ) VALUES (
                COALESCE((SELECT nom_utilisateur FROM session_actuelle LIMIT 1), 'SYSTEM'),
                'UPDATE',
                '{nom_table}',
                NEW.id,
                json_object({colonnes_json_old}),
                json_object({colonnes_json}),
                CURRENT_TIMESTAMP
            );
        END;
        """

        # Trigger DELETE
        trigger_delete = f"""
        CREATE TRIGGER IF NOT EXISTS audit_{nom_table}_delete
        AFTER DELETE ON {nom_table}
        FOR EACH ROW
        BEGIN
            INSERT INTO audit_log (
                nom_utilisateur, action, table_cible, enregistrement_id,
                anciennes_valeurs, timestamp
            ) VALUES (
                COALESCE((SELECT nom_utilisateur FROM session_actuelle LIMIT 1), 'SYSTEM'),
                'DELETE',
                '{nom_table}',
                OLD.id,
                json_object({colonnes_json_old}),
                CURRENT_TIMESTAMP
            );
        END;
        """

        # Ex√©cuter les triggers
        cursor.execute(trigger_insert)
        cursor.execute(trigger_update)
        cursor.execute(trigger_delete)

        conn.commit()
        conn.close()

        print(f"‚úÖ Triggers d'audit cr√©√©s pour la table '{nom_table}'")

    def supprimer_triggers_audit_table(self, nom_table: str):
        """Supprime les triggers d'audit pour une table"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        triggers = [
            f"audit_{nom_table}_insert",
            f"audit_{nom_table}_update",
            f"audit_{nom_table}_delete"
        ]

        for trigger in triggers:
            cursor.execute(f"DROP TRIGGER IF EXISTS {trigger}")

        conn.commit()
        conn.close()

        print(f"‚úÖ Triggers d'audit supprim√©s pour la table '{nom_table}'")

# Exemple d'utilisation
audit_auto = AuditAutomatique('ma_base.db')

# Cr√©er les triggers pour la table clients
audit_auto.creer_triggers_audit_table(
    'clients',
    ['nom', 'email', 'telephone', 'date_creation']
)

# D√©finir l'utilisateur actuel
audit_auto.definir_utilisateur_session('alice')

# Maintenant, toutes les modifications de la table clients seront audit√©es automatiquement
conn = sqlite3.connect('ma_base.db')
cursor = conn.cursor()

# Cette insertion sera automatiquement audit√©e
cursor.execute("""
    INSERT INTO clients (nom, email, telephone)
    VALUES ('Test Client', 'test@email.com', '0123456789')
""")

conn.commit()
conn.close()

print("‚úÖ Insertion effectu√©e et audit√©e automatiquement")
```

## Logging des performances et erreurs

### Syst√®me de logging des performances

```python
import time
import logging
from contextlib import contextmanager
from functools import wraps

class SQLitePerformanceLogger:
    def __init__(self, chemin_base: str, seuil_lent_ms: int = 1000):
        self.chemin_base = chemin_base
        self.seuil_lent_ms = seuil_lent_ms
        self.audit_manager = AuditManager(chemin_base)

        # Configuration du logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('sqlite_performance.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('SQLitePerformance')

    @contextmanager
    def mesurer_requete(self, requete_sql: str, description: str = ""):
        """Context manager pour mesurer le temps d'ex√©cution d'une requ√™te"""
        debut = time.time()
        debut_ms = int(time.time() * 1000)

        try:
            yield

        finally:
            fin = time.time()
            duree_ms = int((fin - debut) * 1000)

            # Logger les requ√™tes lentes
            if duree_ms > self.seuil_lent_ms:
                self.logger.warning(
                    f"REQU√äTE LENTE ({duree_ms}ms): {description}\nSQL: {requete_sql[:200]}..."
                )

                # Enregistrer dans l'audit
                self.audit_manager.enregistrer_operation(
                    action='SLOW_QUERY',
                    table_cible='performance',
                    nouvelles_valeurs={
                        'sql': requete_sql[:500],
                        'description': description,
                        'duree_ms': duree_ms
                    },
                    duree_ms=duree_ms,
                    statut='WARNING'
                )
            else:
                self.logger.debug(f"Requ√™te OK ({duree_ms}ms): {description}")

    def decorator_mesure_performance(self, description: str = ""):
        """D√©corateur pour mesurer automatiquement les performances"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                avec_description = description or f"{func.__name__}"

                debut = time.time()

                try:
                    resultat = func(*args, **kwargs)
                    statut = 'SUCCESS'
                    erreur = None
                except Exception as e:
                    resultat = None
                    statut = 'ERROR'
                    erreur = str(e)
                    raise
                finally:
                    fin = time.time()
                    duree_ms = int((fin - debut) * 1000)

                    # Logger la performance
                    if statut == 'ERROR':
                        self.logger.error(f"ERREUR ({duree_ms}ms): {avec_description} - {erreur}")
                    elif duree_ms > self.seuil_lent_ms:
                        self.logger.warning(f"LENT ({duree_ms}ms): {avec_description}")
                    else:
                        self.logger.debug(f"OK ({duree_ms}ms): {avec_description}")

                    # Enregistrer dans l'audit
                    self.audit_manager.enregistrer_operation(
                        action='FUNCTION_CALL',
                        table_cible='performance',
                        nouvelles_valeurs={
                            'fonction': func.__name__,
                            'description': avec_description,
                            'args': str(args)[:200],
                            'kwargs': str(kwargs)[:200]
                        },
                        duree_ms=duree_ms,
                        statut=statut,
                        message_erreur=erreur
                    )

                return resultat
            return wrapper
        return decorator

# Exemple d'utilisation du logging de performance
perf_logger = SQLitePerformanceLogger('ma_base.db', seuil_lent_ms=500)

# Utilisation avec context manager
def rechercher_clients_complexe(terme):
    conn = sqlite3.connect('ma_base.db')
    cursor = conn.cursor()

    requete = """
        SELECT c.*, COUNT(co.id) as nb_commandes
        FROM clients c
        LEFT JOIN commandes co ON c.id = co.client_id
        WHERE c.nom LIKE ? OR c.email LIKE ?
        GROUP BY c.id
        ORDER BY nb_commandes DESC
    """

    with perf_logger.mesurer_requete(requete, "Recherche clients avec commandes"):
        cursor.execute(requete, (f'%{terme}%', f'%{terme}%'))
        resultats = cursor.fetchall()

    conn.close()
    return resultats

# Utilisation avec d√©corateur
@perf_logger.decorator_mesure_performance("Cr√©ation client avec validation")
def creer_client_complet(nom, email, telephone):
    """Cr√©e un client avec validation compl√®te"""
    conn = sqlite3.connect('ma_base.db')
    cursor = conn.cursor()

    # Validation email unique
    cursor.execute("SELECT id FROM clients WHERE email = ?", (email,))
    if cursor.fetchone():
        raise ValueError("Email d√©j√† utilis√©")

    # Insertion
    cursor.execute("""
        INSERT INTO clients (nom, email, telephone, date_creation)
        VALUES (?, ?, ?, CURRENT_TIMESTAMP)
    """, (nom, email, telephone))

    client_id = cursor.lastrowid
    conn.commit()
    conn.close()

    return client_id

# Test des fonctions avec logging automatique
print("=== TEST LOGGING PERFORMANCE ===")

# Test recherche (devrait √™tre rapide)
resultats = rechercher_clients_complexe("test")

# Test cr√©ation (devrait √™tre rapide)
try:
    nouveau_client = creer_client_complet("Test User", "test@example.com", "0123456789")
    print(f"Client cr√©√© avec ID: {nouveau_client}")
except Exception as e:
    print(f"Erreur cr√©ation client: {e}")
```

## Analyse et reporting des logs d'audit

### G√©n√©rateur de rapports d'audit

```python
import sqlite3
import json
from datetime import datetime, timedelta
from collections import defaultdict

class RapportAudit:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base

    def generer_rapport_activite(self, jours: int = 7):
        """G√©n√®re un rapport d'activit√© pour les X derniers jours"""
        print(f"üìä RAPPORT D'ACTIVIT√â - {jours} derniers jours")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=jours)

        # 1. Statistiques g√©n√©rales
        cursor.execute("""
            SELECT COUNT(*) as total_operations,
                   COUNT(DISTINCT utilisateur_id) as utilisateurs_actifs,
                   COUNT(DISTINCT table_cible) as tables_modifiees
            FROM audit_log
            WHERE timestamp > ?
        """, (date_debut,))

        stats = cursor.fetchone()
        print(f"üìà Statistiques g√©n√©rales:")
        print(f"   ‚Ä¢ Total op√©rations: {stats[0]:,}")
        print(f"   ‚Ä¢ Utilisateurs actifs: {stats[1]}")
        print(f"   ‚Ä¢ Tables modifi√©es: {stats[2]}")
        print()

        # 2. R√©partition par action
        cursor.execute("""
            SELECT action, COUNT(*) as count
            FROM audit_log
            WHERE timestamp > ?
            GROUP BY action
            ORDER BY count DESC
        """, (date_debut,))

        print("üîÑ R√©partition par type d'action:")
        for action, count in cursor.fetchall():
            print(f"   ‚Ä¢ {action}: {count:,}")
        print()

        # 3. Utilisateurs les plus actifs
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as operations
            FROM audit_log
            WHERE timestamp > ? AND nom_utilisateur IS NOT NULL
            GROUP BY nom_utilisateur
            ORDER BY operations DESC
            LIMIT 10
        """, (date_debut,))

        print("üë§ Utilisateurs les plus actifs:")
        for utilisateur, operations in cursor.fetchall():
            print(f"   ‚Ä¢ {utilisateur}: {operations:,} op√©rations")
        print()

        # 4. Tables les plus modifi√©es
        cursor.execute("""
            SELECT table_cible, COUNT(*) as modifications
            FROM audit_log
            WHERE timestamp > ? AND table_cible IS NOT NULL
            GROUP BY table_cible
            ORDER BY modifications DESC
            LIMIT 10
        """, (date_debut,))

        print("üìã Tables les plus modifi√©es:")
        for table, modifications in cursor.fetchall():
            print(f"   ‚Ä¢ {table}: {modifications:,} modifications")
        print()

        # 5. Erreurs et probl√®mes
        cursor.execute("""
            SELECT statut, COUNT(*) as count
            FROM audit_log
            WHERE timestamp > ? AND statut != 'SUCCESS'
            GROUP BY statut
        """, (date_debut,))

        erreurs = cursor.fetchall()
        if erreurs:
            print("‚ö†Ô∏è Erreurs d√©tect√©es:")
            for statut, count in erreurs:
                print(f"   ‚Ä¢ {statut}: {count}")
        else:
            print("‚úÖ Aucune erreur d√©tect√©e")

        conn.close()

    def generer_rapport_securite(self, jours: int = 30):
        """G√©n√®re un rapport de s√©curit√©"""
        print(f"\nüîê RAPPORT DE S√âCURIT√â - {jours} derniers jours")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=jours)

        # 1. √âv√©nements de s√©curit√©
        cursor.execute("""
            SELECT type_evenement, niveau_gravite, COUNT(*) as count
            FROM audit_securite
            WHERE timestamp > ?
            GROUP BY type_evenement, niveau_gravite
            ORDER BY
                CASE niveau_gravite
                    WHEN 'CRITICAL' THEN 1
                    WHEN 'WARNING' THEN 2
                    ELSE 3
                END,
                count DESC
        """, (date_debut,))

        print("üö® √âv√©nements de s√©curit√©:")
        for event_type, niveau, count in cursor.fetchall():
            emoji = "üî¥" if niveau == "CRITICAL" else "üü°" if niveau == "WARNING" else "üü¢"
            print(f"   {emoji} {event_type} ({niveau}): {count}")
        print()

        # 2. Tentatives de connexion √©chou√©es
        cursor.execute("""
            SELECT adresse_ip, COUNT(*) as tentatives
            FROM audit_securite
            WHERE timestamp > ?
              AND type_evenement = 'FAILED_LOGIN'
            GROUP BY adresse_ip
            HAVING tentatives > 3
            ORDER BY tentatives DESC
        """, (date_debut,))

        tentatives_suspectes = cursor.fetchall()
        if tentatives_suspectes:
            print("üö® Adresses IP suspectes (multiples √©checs de connexion):")
            for ip, tentatives in tentatives_suspectes:
                print(f"   ‚Ä¢ {ip}: {tentatives} tentatives √©chou√©es")
        else:
            print("‚úÖ Aucune activit√© suspecte de connexion d√©tect√©e")
        print()

        # 3. Acc√®s aux donn√©es sensibles
        cursor.execute("""
            SELECT nom_utilisateur, table_cible, COUNT(*) as acces
            FROM audit_log
            WHERE timestamp > ?
              AND table_cible IN ('utilisateurs', 'salaires', 'donnees_personnelles')
              AND action = 'SELECT'
            GROUP BY nom_utilisateur, table_cible
            ORDER BY acces DESC
        """, (date_debut,))

        acces_sensibles = cursor.fetchall()
        if acces_sensibles:
            print("üîç Acc√®s aux donn√©es sensibles:")
            for utilisateur, table, acces in acces_sensibles:
                print(f"   ‚Ä¢ {utilisateur} ‚Üí {table}: {acces} consultations")
        else:
            print("‚ÑπÔ∏è Aucun acc√®s aux donn√©es sensibles enregistr√©")
        print()

        # 4. Modifications en dehors des heures de bureau
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as modifications_nocturnes
            FROM audit_log
            WHERE timestamp > ?
              AND action IN ('INSERT', 'UPDATE', 'DELETE')
              AND (CAST(strftime('%H', timestamp) AS INTEGER) < 8
                   OR CAST(strftime('%H', timestamp) AS INTEGER) > 18)
            GROUP BY nom_utilisateur
            ORDER BY modifications_nocturnes DESC
        """, (date_debut,))

        modifications_nocturnes = cursor.fetchall()
        if modifications_nocturnes:
            print("üåô Modifications en dehors des heures de bureau:")
            for utilisateur, count in modifications_nocturnes:
                print(f"   ‚Ä¢ {utilisateur}: {count} modifications nocturnes")
        else:
            print("‚úÖ Toutes les modifications ont eu lieu en heures de bureau")

        conn.close()

    def generer_rapport_performance(self, jours: int = 7):
        """G√©n√®re un rapport de performance"""
        print(f"\n‚ö° RAPPORT DE PERFORMANCE - {jours} derniers jours")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=jours)

        # 1. Requ√™tes les plus lentes
        cursor.execute("""
            SELECT table_cible, action, AVG(duree_ms) as duree_moyenne,
                   MAX(duree_ms) as duree_max, COUNT(*) as occurrences
            FROM audit_log
            WHERE timestamp > ?
              AND duree_ms IS NOT NULL
              AND duree_ms > 100
            GROUP BY table_cible, action
            ORDER BY duree_moyenne DESC
            LIMIT 10
        """, (date_debut,))

        print("üêå Op√©rations les plus lentes (>100ms):")
        for table, action, moy, max_duree, count in cursor.fetchall():
            print(f"   ‚Ä¢ {table}.{action}: {moy:.1f}ms moyenne, {max_duree}ms max ({count} fois)")
        print()

        # 2. Volume d'op√©rations par heure
        cursor.execute("""
            SELECT strftime('%H', timestamp) as heure, COUNT(*) as operations
            FROM audit_log
            WHERE timestamp > ?
            GROUP BY strftime('%H', timestamp)
            ORDER BY heure
        """, (date_debut,))

        print("üìä R√©partition par heure de la journ√©e:")
        for heure, operations in cursor.fetchall():
            barre = "‚ñà" * min(int(operations / 10), 20)  # Graphique simple
            print(f"   {heure}h: {operations:4} ops {barre}")
        print()

        # 3. Erreurs de performance
        cursor.execute("""
            SELECT COUNT(*) as requetes_lentes
            FROM audit_log
            WHERE timestamp > ? AND duree_ms > 1000
        """, (date_debut,))

        requetes_lentes = cursor.fetchone()[0]
        if requetes_lentes > 0:
            print(f"‚ö†Ô∏è {requetes_lentes} requ√™tes tr√®s lentes (>1s) d√©tect√©es")
        else:
            print("‚úÖ Aucune requ√™te tr√®s lente d√©tect√©e")

        conn.close()

    def detecter_anomalies(self):
        """D√©tecte des comportements anormaux dans les logs"""
        print("\nüîç D√âTECTION D'ANOMALIES")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        anomalies = []

        # 1. Utilisateurs avec activit√© inhabituelle
        cursor.execute("""
            WITH stats_utilisateur AS (
                SELECT nom_utilisateur,
                       COUNT(*) as operations_aujourd_hui,
                       AVG(COUNT(*)) OVER() as moyenne_generale
                FROM audit_log
                WHERE date(timestamp) = date('now')
                GROUP BY nom_utilisateur
            )
            SELECT nom_utilisateur, operations_aujourd_hui, moyenne_generale
            FROM stats_utilisateur
            WHERE operations_aujourd_hui > moyenne_generale * 3
        """)

        utilisateurs_hyperactifs = cursor.fetchall()
        if utilisateurs_hyperactifs:
            for user, ops, moyenne in utilisateurs_hyperactifs:
                anomalies.append(f"Utilisateur {user}: {ops} op√©rations (moyenne: {moyenne:.1f})")

        # 2. Suppressions massives
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as suppressions
            FROM audit_log
            WHERE action = 'DELETE'
              AND date(timestamp) = date('now')
            GROUP BY nom_utilisateur
            HAVING suppressions > 10
        """)

        suppressions_massives = cursor.fetchall()
        if suppressions_massives:
            for user, count in suppressions_massives:
                anomalies.append(f"Suppressions massives par {user}: {count} enregistrements")

        # 3. Connexions multiples depuis diff√©rentes IP pour le m√™me utilisateur
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(DISTINCT adresse_ip) as ips_differentes
            FROM audit_securite
            WHERE type_evenement = 'LOGIN'
              AND date(timestamp) = date('now')
            GROUP BY nom_utilisateur
            HAVING ips_differentes > 2
        """)

        connexions_multiples = cursor.fetchall()
        if connexions_multiples:
            for user, ips in connexions_multiples:
                anomalies.append(f"Connexions multiples pour {user}: {ips} adresses IP diff√©rentes")

        # 4. Modifications de donn√©es en cascade (possibles scripts automatiques)
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as modifications_rapides
            FROM audit_log
            WHERE action IN ('INSERT', 'UPDATE', 'DELETE')
              AND timestamp > datetime('now', '-1 hour')
            GROUP BY nom_utilisateur
            HAVING modifications_rapides > 50
        """)

        modifications_rapides = cursor.fetchall()
        if modifications_rapides:
            for user, count in modifications_rapides:
                anomalies.append(f"Modifications tr√®s fr√©quentes par {user}: {count} en 1 heure")

        # Afficher les r√©sultats
        if anomalies:
            print("üö® Anomalies d√©tect√©es:")
            for anomalie in anomalies:
                print(f"   ‚Ä¢ {anomalie}")
            print("\nüí° Recommandations:")
            print("   - V√©rifier l'activit√© de ces utilisateurs")
            print("   - Analyser les logs d√©taill√©s")
            print("   - Contacter les utilisateurs si n√©cessaire")
        else:
            print("‚úÖ Aucune anomalie d√©tect√©e")

        conn.close()
        return anomalies

# Utilisation des rapports
rapport = RapportAudit('ma_base.db')

print("=== G√âN√âRATION DES RAPPORTS D'AUDIT ===")
rapport.generer_rapport_activite(7)
rapport.generer_rapport_securite(30)
rapport.generer_rapport_performance(7)
anomalies = rapport.detecter_anomalies()
```

## Int√©gration avec des outils de monitoring externes

### Export vers des formats standards

```python
import csv
import json
from datetime import datetime

class ExporteurAudit:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base

    def exporter_csv(self, nom_fichier: str, jours: int = 30):
        """Exporte les logs d'audit en CSV"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=jours)

        cursor.execute("""
            SELECT timestamp, nom_utilisateur, action, table_cible,
                   enregistrement_id, adresse_ip, duree_ms, statut
            FROM audit_log
            WHERE timestamp > ?
            ORDER BY timestamp DESC
        """, (date_debut,))

        with open(nom_fichier, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)

            # En-t√™tes
            writer.writerow([
                'Timestamp', 'Utilisateur', 'Action', 'Table',
                'ID_Enregistrement', 'Adresse_IP', 'Duree_ms', 'Statut'
            ])

            # Donn√©es
            for row in cursor.fetchall():
                writer.writerow(row)

        conn.close()
        print(f"‚úÖ Export CSV cr√©√©: {nom_fichier}")

    def exporter_json(self, nom_fichier: str, jours: int = 30):
        """Exporte les logs d'audit en JSON"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=jours)

        cursor.execute("""
            SELECT id, timestamp, nom_utilisateur, action, table_cible,
                   enregistrement_id, anciennes_valeurs, nouvelles_valeurs,
                   adresse_ip, session_id, duree_ms, statut, message_erreur
            FROM audit_log
            WHERE timestamp > ?
            ORDER BY timestamp DESC
        """, (date_debut,))

        logs = []
        for row in cursor.fetchall():
            log_entry = {
                'id': row[0],
                'timestamp': row[1],
                'utilisateur': row[2],
                'action': row[3],
                'table': row[4],
                'enregistrement_id': row[5],
                'anciennes_valeurs': json.loads(row[6]) if row[6] else None,
                'nouvelles_valeurs': json.loads(row[7]) if row[7] else None,
                'adresse_ip': row[8],
                'session_id': row[9],
                'duree_ms': row[10],
                'statut': row[11],
                'message_erreur': row[12]
            }
            logs.append(log_entry)

        with open(nom_fichier, 'w', encoding='utf-8') as jsonfile:
            json.dump({
                'export_date': datetime.now().isoformat(),
                'periode_jours': jours,
                'total_entries': len(logs),
                'logs': logs
            }, jsonfile, indent=2, ensure_ascii=False)

        conn.close()
        print(f"‚úÖ Export JSON cr√©√©: {nom_fichier}")

    def generer_metriques_prometheus(self, nom_fichier: str):
        """G√©n√®re des m√©triques au format Prometheus"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # M√©triques des derni√®res 24h
        cursor.execute("""
            SELECT action, COUNT(*) as count
            FROM audit_log
            WHERE timestamp > datetime('now', '-1 day')
            GROUP BY action
        """)

        metriques = []

        # M√©trique du nombre d'op√©rations par type
        for action, count in cursor.fetchall():
            metriques.append(f'sqlite_operations_total{{action="{action.lower()}"}} {count}')

        # M√©trique des erreurs
        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > datetime('now', '-1 day') AND statut != 'SUCCESS'
        """)
        erreurs = cursor.fetchone()[0]
        metriques.append(f'sqlite_errors_total {erreurs}')

        # M√©trique du temps de r√©ponse moyen
        cursor.execute("""
            SELECT AVG(duree_ms) FROM audit_log
            WHERE timestamp > datetime('now', '-1 day') AND duree_ms IS NOT NULL
        """)
        duree_moyenne = cursor.fetchone()[0] or 0
        metriques.append(f'sqlite_response_time_avg_ms {duree_moyenne:.2f}')

        # M√©trique des utilisateurs actifs
        cursor.execute("""
            SELECT COUNT(DISTINCT nom_utilisateur) FROM audit_log
            WHERE timestamp > datetime('now', '-1 day')
        """)
        utilisateurs_actifs = cursor.fetchone()[0]
        metriques.append(f'sqlite_active_users {utilisateurs_actifs}')

        with open(nom_fichier, 'w') as f:
            f.write("# M√©triques SQLite\n")
            f.write("# HELP sqlite_operations_total Nombre total d'op√©rations par type\n")
            f.write("# TYPE sqlite_operations_total counter\n")
            for metrique in metriques:
                f.write(metrique + '\n')

        conn.close()
        print(f"‚úÖ M√©triques Prometheus cr√©√©es: {nom_fichier}")

# Utilisation des exportateurs
exporteur = ExporteurAudit('ma_base.db')

print("=== EXPORT DES DONN√âES D'AUDIT ===")
exporteur.exporter_csv('audit_export.csv', 30)
exporteur.exporter_json('audit_export.json', 30)
exporteur.generer_metriques_prometheus('sqlite_metrics.prom')
```

### Int√©gration avec des syst√®mes de log centralis√©s

```python
import requests
import syslog
from datetime import datetime

class IntegrationMonitoring:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base
        self.audit_manager = AuditManager(chemin_base)

    def envoyer_vers_elastic(self, url_elastic: str, index_name: str = "sqlite-audit"):
        """Envoie les logs vers Elasticsearch"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # R√©cup√©rer les logs non envoy√©s (supposons qu'on ait un flag)
        cursor.execute("""
            SELECT id, timestamp, nom_utilisateur, action, table_cible,
                   enregistrement_id, anciennes_valeurs, nouvelles_valeurs,
                   adresse_ip, duree_ms, statut
            FROM audit_log
            WHERE timestamp > datetime('now', '-1 hour')
            ORDER BY timestamp ASC
        """)

        logs_envoyes = 0

        for log_entry in cursor.fetchall():
            doc = {
                "@timestamp": log_entry[1],
                "user": log_entry[2],
                "action": log_entry[3],
                "table": log_entry[4],
                "record_id": log_entry[5],
                "old_values": json.loads(log_entry[6]) if log_entry[6] else None,
                "new_values": json.loads(log_entry[7]) if log_entry[7] else None,
                "ip_address": log_entry[8],
                "duration_ms": log_entry[9],
                "status": log_entry[10],
                "source": "sqlite_audit"
            }

            try:
                response = requests.post(
                    f"{url_elastic}/{index_name}/_doc",
                    json=doc,
                    headers={"Content-Type": "application/json"}
                )

                if response.status_code in [200, 201]:
                    logs_envoyes += 1
                else:
                    print(f"Erreur Elasticsearch: {response.status_code}")

            except Exception as e:
                print(f"Erreur envoi Elasticsearch: {e}")

        conn.close()
        print(f"‚úÖ {logs_envoyes} logs envoy√©s vers Elasticsearch")

    def envoyer_vers_syslog(self, serveur_syslog: str = 'localhost', port: int = 514):
        """Envoie les √©v√©nements critiques vers syslog"""
        syslog.openlog("sqlite_audit", syslog.LOG_PID, syslog.LOG_LOCAL0)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # √âv√©nements critiques des derni√®res minutes
        cursor.execute("""
            SELECT type_evenement, nom_utilisateur, adresse_ip, details
            FROM audit_securite
            WHERE timestamp > datetime('now', '-5 minutes')
              AND niveau_gravite = 'CRITICAL'
        """)

        for event_type, user, ip, details in cursor.fetchall():
            message = f"SQLITE_CRITICAL: {event_type} by {user} from {ip}"
            if details:
                message += f" - {details}"

            syslog.syslog(syslog.LOG_CRIT, message)

        syslog.closelog()
        conn.close()

    def webhook_alertes(self, webhook_url: str, seuil_erreurs: int = 5):
        """Envoie des alertes via webhook (Slack, Teams, etc.)"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # Compter les erreurs r√©centes
        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > datetime('now', '-15 minutes')
              AND statut != 'SUCCESS'
        """)

        erreurs_recentes = cursor.fetchone()[0]

        if erreurs_recentes >= seuil_erreurs:
            # R√©cup√©rer les d√©tails des erreurs
            cursor.execute("""
                SELECT action, table_cible, message_erreur, COUNT(*) as count
                FROM audit_log
                WHERE timestamp > datetime('now', '-15 minutes')
                  AND statut != 'SUCCESS'
                GROUP BY action, table_cible, message_erreur
                ORDER BY count DESC
            """)

            erreurs_detail = cursor.fetchall()

            # Construire le message d'alerte
            message = {
                "text": f"üö® ALERTE SQLite: {erreurs_recentes} erreurs d√©tect√©es",
                "attachments": [{
                    "color": "danger",
                    "fields": [
                        {
                            "title": "P√©riode",
                            "value": "15 derni√®res minutes",
                            "short": True
                        },
                        {
                            "title": "Total erreurs",
                            "value": str(erreurs_recentes),
                            "short": True
                        }
                    ]
                }]
            }

            # Ajouter les d√©tails des erreurs
            details_text = ""
            for action, table, erreur, count in erreurs_detail[:5]:  # Limiter √† 5
                details_text += f"‚Ä¢ {action} sur {table}: {count} fois\\n"
                if erreur:
                    details_text += f"  Erreur: {erreur[:100]}...\\n"

            message["attachments"][0]["fields"].append({
                "title": "D√©tails des erreurs",
                "value": details_text,
                "short": False
            })

            try:
                response = requests.post(webhook_url, json=message)
                if response.status_code == 200:
                    print("‚úÖ Alerte envoy√©e via webhook")
                else:
                    print(f"‚ùå Erreur envoi webhook: {response.status_code}")
            except Exception as e:
                print(f"‚ùå Erreur webhook: {e}")

        conn.close()

# Configuration et utilisation du monitoring
monitoring = IntegrationMonitoring('ma_base.db')

# Exemple d'utilisation
print("=== INT√âGRATION MONITORING EXTERNE ===")

# Note: Ces URL sont des exemples, adaptez selon votre infrastructure
# monitoring.envoyer_vers_elastic('http://localhost:9200', 'sqlite-audit')
# monitoring.envoyer_vers_syslog('log-server.example.com', 514)
# monitoring.webhook_alertes('https://hooks.slack.com/services/YOUR/WEBHOOK/URL')

print("Configuration monitoring disponible - adaptez les URL selon votre infrastructure")
```

## Maintenance et optimisation des logs

### Nettoyage automatique des logs

```python
from datetime import datetime, timedelta
import os

class MaintenanceLogs:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base

    def nettoyer_logs_anciens(self, jours_retention: int = 90):
        """Supprime les logs plus anciens que la p√©riode de r√©tention"""
        print(f"üßπ Nettoyage des logs de plus de {jours_retention} jours...")

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_limite = datetime.now() - timedelta(days=jours_retention)

        # Compter les logs √† supprimer
        cursor.execute("SELECT COUNT(*) FROM audit_log WHERE timestamp < ?", (date_limite,))
        logs_a_supprimer = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM audit_securite WHERE timestamp < ?", (date_limite,))
        securite_a_supprimer = cursor.fetchone()[0]

        if logs_a_supprimer > 0 or securite_a_supprimer > 0:
            print(f"   üìä {logs_a_supprimer} entr√©es audit_log √† supprimer")
            print(f"   üîê {securite_a_supprimer} entr√©es audit_securite √† supprimer")

            # Effectuer le nettoyage
            cursor.execute("DELETE FROM audit_log WHERE timestamp < ?", (date_limite,))
            cursor.execute("DELETE FROM audit_securite WHERE timestamp < ?", (date_limite,))

            conn.commit()
            print("   ‚úÖ Nettoyage termin√©")
        else:
            print("   ‚ÑπÔ∏è Aucun log ancien √† supprimer")

        conn.close()

    def archiver_logs_anciens(self, jours_archive: int = 365, chemin_archive: str = "archive"):
        """Archive les logs anciens dans des fichiers s√©par√©s"""
        print(f"üì¶ Archivage des logs de plus de {jours_archive} jours...")

        os.makedirs(chemin_archive, exist_ok=True)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_limite = datetime.now() - timedelta(days=jours_archive)
        timestamp_archive = datetime.now().strftime('%Y%m%d_%H%M%S')

        # Archive des logs d'audit
        fichier_archive = os.path.join(chemin_archive, f"audit_log_{timestamp_archive}.json")

        cursor.execute("""
            SELECT * FROM audit_log WHERE timestamp < ?
            ORDER BY timestamp
        """, (date_limite,))

        logs_archives = []
        for row in cursor.fetchall():
            logs_archives.append({
                'id': row[0],
                'timestamp': row[1],
                'utilisateur_id': row[2],
                'nom_utilisateur': row[3],
                'action': row[4],
                'table_cible': row[5],
                'enregistrement_id': row[6],
                'anciennes_valeurs': json.loads(row[7]) if row[7] else None,
                'nouvelles_valeurs': json.loads(row[8]) if row[8] else None,
                'adresse_ip': row[9],
                'session_id': row[10],
                'duree_ms': row[11],
                'statut': row[12],
                'message_erreur': row[13]
            })

        if logs_archives:
            with open(fichier_archive, 'w', encoding='utf-8') as f:
                json.dump({
                    'archive_date': datetime.now().isoformat(),
                    'total_entries': len(logs_archives),
                    'logs': logs_archives
                }, f, indent=2, ensure_ascii=False)

            # Supprimer les logs archiv√©s
            cursor.execute("DELETE FROM audit_log WHERE timestamp < ?", (date_limite,))

            print(f"   ‚úÖ {len(logs_archives)} logs archiv√©s dans {fichier_archive}")
        else:
            print("   ‚ÑπÔ∏è Aucun log √† archiver")

        conn.commit()
        conn.close()

    def optimiser_base_audit(self):
        """Optimise la base de donn√©es d'audit"""
        print("‚ö° Optimisation de la base d'audit...")

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # Analyser la taille avant optimisation
        cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
        taille_avant = cursor.fetchone()[0]

        # Ex√©cuter l'optimisation
        print("   üîÑ VACUUM en cours...")
        cursor.execute("VACUUM")

        print("   üìä ANALYZE en cours...")
        cursor.execute("ANALYZE")

        print("   ‚öôÔ∏è Optimisation automatique...")
        cursor.execute("PRAGMA optimize")

        # Analyser la taille apr√®s optimisation
        cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
        taille_apres = cursor.fetchone()[0]

        espace_libere = taille_avant - taille_apres
        pourcentage = (espace_libere / taille_avant) * 100 if taille_avant > 0 else 0

        print(f"   ‚úÖ Optimisation termin√©e")
        print(f"   üìâ Espace lib√©r√©: {espace_libere / 1024 / 1024:.2f} MB ({pourcentage:.1f}%)")

        conn.close()

    def verifier_integrite_logs(self):
        """V√©rifie l'int√©grit√© des tables de logs"""
        print("üîç V√©rification de l'int√©grit√© des logs...")

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # V√©rification g√©n√©rale
        cursor.execute("PRAGMA integrity_check")
        resultat_integrite = cursor.fetchone()[0]

        if resultat_integrite == 'ok':
            print("   ‚úÖ Int√©grit√© g√©n√©rale: OK")
        else:
            print(f"   ‚ùå Probl√®me d'int√©grit√©: {resultat_integrite}")

        # V√©rifications sp√©cifiques aux logs
        verifications = []

        # 1. Logs orphelins (utilisateur supprim√©)
        cursor.execute("""
            SELECT COUNT(*) FROM audit_log al
            LEFT JOIN utilisateurs u ON al.utilisateur_id = u.id
            WHERE al.utilisateur_id IS NOT NULL AND u.id IS NULL
        """)
        logs_orphelins = cursor.fetchone()[0]
        if logs_orphelins > 0:
            verifications.append(f"‚ö†Ô∏è {logs_orphelins} logs avec utilisateurs inexistants")

        # 2. Logs avec timestamps futurs
        cursor.execute("SELECT COUNT(*) FROM audit_log WHERE timestamp > datetime('now')")
        logs_futurs = cursor.fetchone()[0]
        if logs_futurs > 0:
            verifications.append(f"‚ö†Ô∏è {logs_futurs} logs avec timestamp futur")

        # 3. Logs avec JSON invalide
        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE (anciennes_valeurs IS NOT NULL AND json_valid(anciennes_valeurs) = 0)
               OR (nouvelles_valeurs IS NOT NULL AND json_valid(nouvelles_valeurs) = 0)
        """)
        json_invalides = cursor.fetchone()[0]
        if json_invalides > 0:
            verifications.append(f"‚ö†Ô∏è {json_invalides} logs avec JSON invalide")

        if verifications:
            print("   üîç Probl√®mes d√©tect√©s:")
            for probleme in verifications:
                print(f"      {probleme}")
        else:
            print("   ‚úÖ Tous les contr√¥les sp√©cifiques sont OK")

        conn.close()

# Classe pour automatiser la maintenance
class SchedulerMaintenance:
    def __init__(self, chemin_base: str):
        self.maintenance = MaintenanceLogs(chemin_base)

    def maintenance_quotidienne(self):
        """Routine de maintenance quotidienne"""
        print("üîÑ === MAINTENANCE QUOTIDIENNE ===")
        print(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # 1. V√©rification d'int√©grit√©
        self.maintenance.verifier_integrite_logs()

        # 2. Nettoyage des logs anciens (90 jours par d√©faut)
        self.maintenance.nettoyer_logs_anciens(90)

        # 3. Optimisation l√©g√®re
        self.maintenance.optimiser_base_audit()

        print("‚úÖ Maintenance quotidienne termin√©e\n")

    def maintenance_hebdomadaire(self):
        """Routine de maintenance hebdomadaire"""
        print("üîÑ === MAINTENANCE HEBDOMADAIRE ===")
        print(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # 1. Archivage des logs tr√®s anciens (1 an)
        self.maintenance.archiver_logs_anciens(365, "archive_logs")

        # 2. Optimisation compl√®te
        self.maintenance.optimiser_base_audit()

        # 3. G√©n√©ration des rapports de performance
        rapport = RapportAudit(self.maintenance.chemin_base)
        rapport.generer_rapport_performance(7)

        print("‚úÖ Maintenance hebdomadaire termin√©e\n")

    def maintenance_urgence(self):
        """Maintenance d'urgence en cas de probl√®me"""
        print("üö® === MAINTENANCE D'URGENCE ===")
        print(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # 1. V√©rification d'int√©grit√© imm√©diate
        self.maintenance.verifier_integrite_logs()

        # 2. Sauvegarde d'urgence
        import shutil
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_path = f"{self.maintenance.chemin_base}.emergency_backup_{timestamp}"
        shutil.copy2(self.maintenance.chemin_base, backup_path)
        print(f"   üíæ Sauvegarde d'urgence: {backup_path}")

        # 3. Nettoyage agressif si n√©cessaire
        self.maintenance.nettoyer_logs_anciens(30)  # Plus agressif

        print("‚úÖ Maintenance d'urgence termin√©e\n")

# Utilisation de la maintenance automatis√©e
scheduler = SchedulerMaintenance('ma_base.db')

print("=== D√âMONSTRATION MAINTENANCE ===")
scheduler.maintenance_quotidienne()
```

## Configuration avanc√©e de l'audit

### Syst√®me d'audit configurable par r√®gles

```python
import yaml
from typing import Dict, List

class ConfigurationAudit:
    def __init__(self, chemin_config: str = 'audit_config.yaml'):
        self.chemin_config = chemin_config
        self.config = self._charger_configuration()
        self.audit_manager = None

    def _charger_configuration(self) -> Dict:
        """Charge la configuration depuis un fichier YAML"""
        config_defaut = {
            'audit': {
                'actif': True,
                'niveau_detail': 'COMPLET',  # MINIMAL, STANDARD, COMPLET
                'retention_jours': 90,
                'archivage_jours': 365
            },
            'tables_auditees': {
                'utilisateurs': {
                    'actif': True,
                    'actions': ['INSERT', 'UPDATE', 'DELETE'],
                    'colonnes_sensibles': ['mot_de_passe_hash', 'email'],
                    'niveau_detail': 'COMPLET'
                },
                'commandes': {
                    'actif': True,
                    'actions': ['INSERT', 'UPDATE', 'DELETE'],
                    'colonnes_sensibles': ['montant', 'statut'],
                    'niveau_detail': 'STANDARD'
                },
                'logs_systeme': {
                    'actif': False,
                    'actions': ['DELETE'],
                    'niveau_detail': 'MINIMAL'
                }
            },
            'alertes': {
                'erreurs_consecutives': 5,
                'operations_massives': 100,
                'connexions_echouees': 10,
                'webhook_url': None,
                'email_admin': None
            },
            'performance': {
                'seuil_requete_lente_ms': 1000,
                'log_requetes_lentes': True,
                'optimisation_auto': True
            },
            'securite': {
                'masquer_donnees_sensibles': True,
                'chiffrer_logs': False,
                'ip_autorisees': [],
                'heures_maintenance': ['02:00', '03:00']
            }
        }

        try:
            with open(self.chemin_config, 'r', encoding='utf-8') as f:
                config_fichier = yaml.safe_load(f)
                # Fusionner avec la config par d√©faut
                return {**config_defaut, **config_fichier}
        except FileNotFoundError:
            print(f"‚ö†Ô∏è Fichier de config non trouv√©, cr√©ation de {self.chemin_config}")
            self._sauvegarder_configuration(config_defaut)
            return config_defaut

    def _sauvegarder_configuration(self, config: Dict):
        """Sauvegarde la configuration dans le fichier YAML"""
        with open(self.chemin_config, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)

    def est_table_auditee(self, nom_table: str, action: str) -> bool:
        """V√©rifie si une table/action doit √™tre audit√©e"""
        if not self.config['audit']['actif']:
            return False

        table_config = self.config['tables_auditees'].get(nom_table, {})

        if not table_config.get('actif', False):
            return False

        actions_auditees = table_config.get('actions', [])
        return action.upper() in [a.upper() for a in actions_auditees]

    def obtenir_niveau_detail(self, nom_table: str) -> str:
        """Obtient le niveau de d√©tail pour une table"""
        table_config = self.config['tables_auditees'].get(nom_table, {})
        return table_config.get('niveau_detail', self.config['audit']['niveau_detail'])

    def obtenir_colonnes_sensibles(self, nom_table: str) -> List[str]:
        """Obtient la liste des colonnes sensibles d'une table"""
        table_config = self.config['tables_auditees'].get(nom_table, {})
        return table_config.get('colonnes_sensibles', [])

    def masquer_donnees_sensibles(self, nom_table: str, donnees: Dict) -> Dict:
        """Masque les donn√©es sensibles selon la configuration"""
        if not self.config['securite']['masquer_donnees_sensibles']:
            return donnees

        donnees_masquees = donnees.copy()
        colonnes_sensibles = self.obtenir_colonnes_sensibles(nom_table)

        for colonne in colonnes_sensibles:
            if colonne in donnees_masquees:
                valeur = donnees_masquees[colonne]
                if isinstance(valeur, str) and len(valeur) > 4:
                    # Masquer en gardant les 2 premiers et 2 derniers caract√®res
                    donnees_masquees[colonne] = valeur[:2] + '*' * (len(valeur) - 4) + valeur[-2:]
                else:
                    donnees_masquees[colonne] = '***'

        return donnees_masquees

class AuditManagerAvance(AuditManager):
    """Version avanc√©e du gestionnaire d'audit avec configuration"""

    def __init__(self, chemin_base: str, chemin_config: str = 'audit_config.yaml'):
        super().__init__(chemin_base)
        self.config_audit = ConfigurationAudit(chemin_config)

    def enregistrer_operation_conditionnelle(self, action: str, table_cible: str,
                                           enregistrement_id: int = None,
                                           anciennes_valeurs: Dict = None,
                                           nouvelles_valeurs: Dict = None,
                                           duree_ms: int = None):
        """Enregistre une op√©ration seulement si configur√©e pour √™tre audit√©e"""

        # V√©rifier si l'audit est n√©cessaire
        if not self.config_audit.est_table_auditee(table_cible, action):
            return

        # Obtenir le niveau de d√©tail
        niveau_detail = self.config_audit.obtenir_niveau_detail(table_cible)

        # Adapter les donn√©es selon le niveau de d√©tail
        if niveau_detail == 'MINIMAL':
            anciennes_valeurs = None
            nouvelles_valeurs = None
        elif niveau_detail == 'STANDARD':
            # Masquer les donn√©es sensibles
            if anciennes_valeurs:
                anciennes_valeurs = self.config_audit.masquer_donnees_sensibles(
                    table_cible, anciennes_valeurs
                )
            if nouvelles_valeurs:
                nouvelles_valeurs = self.config_audit.masquer_donnees_sensibles(
                    table_cible, nouvelles_valeurs
                )
        # COMPLET : garder toutes les donn√©es

        # Enregistrer l'op√©ration
        super().enregistrer_operation(
            action=action,
            table_cible=table_cible,
            enregistrement_id=enregistrement_id,
            anciennes_valeurs=anciennes_valeurs,
            nouvelles_valeurs=nouvelles_valeurs,
            duree_ms=duree_ms
        )

    def verifier_alertes(self):
        """V√©rifie si des alertes doivent √™tre d√©clench√©es"""
        config_alertes = self.config_audit.config['alertes']

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        alertes_declenchees = []

        # 1. Erreurs cons√©cutives
        seuil_erreurs = config_alertes['erreurs_consecutives']
        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > datetime('now', '-15 minutes')
              AND statut != 'SUCCESS'
        """)
        erreurs_recentes = cursor.fetchone()[0]

        if erreurs_recentes >= seuil_erreurs:
            alertes_declenchees.append({
                'type': 'ERREURS_CONSECUTIVES',
                'message': f'{erreurs_recentes} erreurs en 15 minutes',
                'gravite': 'CRITICAL'
            })

        # 2. Op√©rations massives
        seuil_operations = config_alertes['operations_massives']
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as operations
            FROM audit_log
            WHERE timestamp > datetime('now', '-1 hour')
              AND action IN ('INSERT', 'UPDATE', 'DELETE')
            GROUP BY nom_utilisateur
            HAVING operations > ?
        """, (seuil_operations,))

        operations_massives = cursor.fetchall()
        for utilisateur, count in operations_massives:
            alertes_declenchees.append({
                'type': 'OPERATIONS_MASSIVES',
                'message': f'{utilisateur}: {count} op√©rations en 1 heure',
                'gravite': 'WARNING'
            })

        # 3. Connexions √©chou√©es
        seuil_connexions = config_alertes['connexions_echouees']
        cursor.execute("""
            SELECT adresse_ip, COUNT(*) as tentatives
            FROM audit_securite
            WHERE timestamp > datetime('now', '-1 hour')
              AND type_evenement = 'FAILED_LOGIN'
            GROUP BY adresse_ip
            HAVING tentatives > ?
        """, (seuil_connexions,))

        connexions_echouees = cursor.fetchall()
        for ip, tentatives in connexions_echouees:
            alertes_declenchees.append({
                'type': 'CONNEXIONS_ECHOUEES',
                'message': f'IP {ip}: {tentatives} tentatives √©chou√©es en 1 heure',
                'gravite': 'CRITICAL'
            })

        conn.close()

        # Envoyer les alertes
        for alerte in alertes_declenchees:
            self._envoyer_alerte(alerte)

        return alertes_declenchees

    def _envoyer_alerte(self, alerte: Dict):
        """Envoie une alerte selon la configuration"""
        config_alertes = self.config_audit.config['alertes']

        message_alerte = f"üö® ALERTE SQLite: {alerte['type']}\n{alerte['message']}"

        # Webhook
        webhook_url = config_alertes.get('webhook_url')
        if webhook_url:
            try:
                import requests
                payload = {
                    "text": message_alerte,
                    "username": "SQLite Audit",
                    "channel": "#alerts"
                }
                requests.post(webhook_url, json=payload, timeout=10)
            except Exception as e:
                print(f"Erreur envoi webhook: {e}")

        # Email (simulation)
        email_admin = config_alertes.get('email_admin')
        if email_admin:
            print(f"üìß Email envoy√© √† {email_admin}: {message_alerte}")

        # Log local
        print(f"üîî {message_alerte}")

# Utilisation de l'audit avanc√©
audit_avance = AuditManagerAvance('ma_base.db')

# D√©finir le contexte
audit_avance.definir_contexte(1, 'alice', 'sess_456', '192.168.1.100')

# Test d'enregistrement conditionnel
print("=== TEST AUDIT CONDITIONNEL ===")

# Cette op√©ration sera audit√©e selon la config
audit_avance.enregistrer_operation_conditionnelle(
    action='UPDATE',
    table_cible='utilisateurs',
    enregistrement_id=1,
    anciennes_valeurs={'email': 'ancien@email.com', 'mot_de_passe_hash': 'hash123'},
    nouvelles_valeurs={'email': 'nouveau@email.com', 'mot_de_passe_hash': 'newhash456'}
)

# V√©rifier les alertes
alertes = audit_avance.verifier_alertes()
if alertes:
    print(f"‚ö†Ô∏è {len(alertes)} alertes d√©clench√©es")
else:
    print("‚úÖ Aucune alerte")
```

## Outils d'analyse forensique

### Reconstruction d'√©v√©nements

```python
from datetime import datetime, timedelta
import networkx as nx
import matplotlib.pyplot as plt

class AnalyseForensique:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base

    def reconstituer_chronologie(self, utilisateur: str = None,
                                table: str = None,
                                enregistrement_id: int = None,
                                heures: int = 24):
        """Reconstitue la chronologie des √©v√©nements"""
        print(f"üîç ANALYSE FORENSIQUE - {heures}h")
        if utilisateur:
            print(f"üë§ Utilisateur: {utilisateur}")
        if table:
            print(f"üìã Table: {table}")
        if enregistrement_id:
            print(f"üÜî Enregistrement: {enregistrement_id}")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # Construire la requ√™te avec filtres
        where_clauses = ["timestamp > datetime('now', '-{} hours')".format(heures)]
        params = []

        if utilisateur:
            where_clauses.append("nom_utilisateur = ?")
            params.append(utilisateur)

        if table:
            where_clauses.append("table_cible = ?")
            params.append(table)

        if enregistrement_id:
            where_clauses.append("enregistrement_id = ?")
            params.append(enregistrement_id)

        where_clause = " AND ".join(where_clauses)

        cursor.execute(f"""
            SELECT timestamp, nom_utilisateur, action, table_cible,
                   enregistrement_id, anciennes_valeurs, nouvelles_valeurs,
                   adresse_ip, statut
            FROM audit_log
            WHERE {where_clause}
            ORDER BY timestamp ASC
        """, params)

        evenements = cursor.fetchall()

        print(f"üìä {len(evenements)} √©v√©nements trouv√©s\n")

        for i, event in enumerate(evenements, 1):
            timestamp, user, action, table_cible, record_id, old_vals, new_vals, ip, statut = event

            status_emoji = "‚úÖ" if statut == "SUCCESS" else "‚ùå"

            print(f"{i:3d}. {timestamp} {status_emoji}")
            print(f"     üë§ {user} @ {ip}")
            print(f"     üîÑ {action} sur {table_cible}")
            if record_id:
                print(f"     üÜî Enregistrement: {record_id}")

            # Afficher les changements
            if action in ['UPDATE', 'DELETE'] and old_vals:
                try:
                    old_data = json.loads(old_vals)
                    print(f"     üì§ Avant: {old_data}")
                except:
                    pass

            if action in ['INSERT', 'UPDATE'] and new_vals:
                try:
                    new_data = json.loads(new_vals)
                    print(f"     üì• Apr√®s: {new_data}")
                except:
                    pass

            print()

        conn.close()
        return evenements

    def analyser_pattern_utilisateur(self, utilisateur: str, jours: int = 7):
        """Analyse les patterns d'activit√© d'un utilisateur"""
        print(f"üìà ANALYSE PATTERN UTILISATEUR: {utilisateur}")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=jours)

        # 1. Activit√© par heure
        cursor.execute("""
            SELECT strftime('%H', timestamp) as heure, COUNT(*) as operations
            FROM audit_log
            WHERE nom_utilisateur = ? AND timestamp > ?
            GROUP BY strftime('%H', timestamp)
            ORDER BY heure
        """, (utilisateur, date_debut))

        print("‚è∞ Activit√© par heure:")
        activite_heures = cursor.fetchall()
        for heure, ops in activite_heures:
            barre = "‚ñà" * min(ops // 2, 20)
            print(f"   {heure}h: {ops:3d} ops {barre}")
        print()

        # 2. Actions les plus fr√©quentes
        cursor.execute("""
            SELECT action, table_cible, COUNT(*) as count
            FROM audit_log
            WHERE nom_utilisateur = ? AND timestamp > ?
            GROUP BY action, table_cible
            ORDER BY count DESC
            LIMIT 10
        """, (utilisateur, date_debut))

        print("üîÑ Actions les plus fr√©quentes:")
        for action, table, count in cursor.fetchall():
            print(f"   ‚Ä¢ {action} sur {table}: {count} fois")
        print()

        # 3. Adresses IP utilis√©es
        cursor.execute("""
            SELECT adresse_ip, COUNT(*) as connexions,
                   MIN(timestamp) as premiere, MAX(timestamp) as derniere
            FROM audit_log
            WHERE nom_utilisateur = ? AND timestamp > ? AND adresse_ip IS NOT NULL
            GROUP BY adresse_ip
            ORDER BY connexions DESC
        """, (utilisateur, date_debut))

        print("üåê Adresses IP utilis√©es:")
        ips = cursor.fetchall()
        for ip, connexions, premiere, derniere in ips:
            print(f"   ‚Ä¢ {ip}: {connexions} connexions ({premiere} ‚Üí {derniere})")

        if len(ips) > 2:
            print("   ‚ö†Ô∏è Utilisateur connect√© depuis plusieurs IP")

        # 4. D√©tection d'anomalies
        print("\nüîç D√©tection d'anomalies:")
        anomalies = []

        # Activit√© nocturne
        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE nom_utilisateur = ? AND timestamp > ?
              AND (CAST(strftime('%H', timestamp) AS INTEGER) < 6
                   OR CAST(strftime('%H', timestamp) AS INTEGER) > 22)
        """, (utilisateur, date_debut))

        activite_nocturne = cursor.fetchone()[0]
        if activite_nocturne > 0:
            anomalies.append(f"Activit√© nocturne: {activite_nocturne} op√©rations")

        # Volume anormalement √©lev√©
        cursor.execute("""
            SELECT COUNT(*) as operations_total FROM audit_log
            WHERE nom_utilisateur = ? AND timestamp > ?
        """, (utilisateur, date_debut))

        total_ops = cursor.fetchone()[0]
        moyenne_quotidienne = total_ops / jours

        if moyenne_quotidienne > 500:  # Seuil arbitraire
            anomalies.append(f"Volume √©lev√©: {moyenne_quotidienne:.0f} ops/jour")

        if anomalies:
            for anomalie in anomalies:
                print(f"   ‚ö†Ô∏è {anomalie}")
        else:
            print("   ‚úÖ Aucune anomalie d√©tect√©e")

        conn.close()

    def generer_graphe_activite(self, heures: int = 24, fichier_sortie: str = "audit_graph.png"):
        """G√©n√®re un graphe des interactions entre utilisateurs et tables"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(hours=heures)

        cursor.execute("""
            SELECT nom_utilisateur, table_cible, COUNT(*) as poids
            FROM audit_log
            WHERE timestamp > ? AND nom_utilisateur IS NOT NULL AND table_cible IS NOT NULL
            GROUP BY nom_utilisateur, table_cible
            ORDER BY poids DESC
        """, (date_debut,))

        interactions = cursor.fetchall()

        # Cr√©er le graphe
        G = nx.Graph()

        for utilisateur, table, poids in interactions:
            G.add_edge(f"üë§{utilisateur}", f"üìã{table}", weight=poids)

        # Dessiner le graphe
        plt.figure(figsize=(12, 8))
        pos = nx.spring_layout(G, k=1, iterations=50)

        # Dessiner les n≈ìuds
        user_nodes = [n for n in G.nodes() if n.startswith('üë§')]
        table_nodes = [n for n in G.nodes() if n.startswith('üìã')]

        nx.draw_networkx_nodes(G, pos, nodelist=user_nodes,
                              node_color='lightblue', node_size=1000, alpha=0.7)
        nx.draw_networkx_nodes(G, pos, nodelist=table_nodes,
                              node_color='lightgreen', node_size=800, alpha=0.7)

        # Dessiner les ar√™tes avec √©paisseur proportionnelle au poids
        edges = G.edges()
        weights = [G[u][v]['weight'] for u, v in edges]
        max_weight = max(weights) if weights else 1

        nx.draw_networkx_edges(G, pos, width=[w/max_weight * 5 for w in weights], alpha=0.6)

        # Ajouter les labels
        nx.draw_networkx_labels(G, pos, font_size=8)

        # Ajouter les poids sur les ar√™tes
        edge_labels = {(u, v): str(d['weight']) for u, v, d in G.edges(data=True)}
        nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=6)

        plt.title(f"Graphe d'activit√© SQLite - {heures}h", fontsize=14)
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(fichier_sortie, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"üìä Graphe d'activit√© sauvegard√©: {fichier_sortie}")

        conn.close()

# Utilisation de l'analyse forensique
forensique = AnalyseForensique('ma_base.db')

print("=== ANALYSE FORENSIQUE ===")

# Reconstituer la chronologie pour un utilisateur sp√©cifique
evenements = forensique.reconstituer_chronologie(
    utilisateur='alice',
    heures=24
)

# Analyser les patterns d'un utilisateur
forensique.analyser_pattern_utilisateur('alice', 7)

# G√©n√©rer le graphe d'activit√©
# forensique.generer_graphe_activite(24, "activite_audit.png")
```

## Conformit√© et reporting r√©glementaire

### G√©n√©rateur de rapports de conformit√©

```python
class ConformiteReglementaire:
    def __init__(self, chemin_base: str):
        self.chemin_base = chemin_base

    def rapport_rgpd(self, periode_jours: int = 30):
        """G√©n√®re un rapport de conformit√© RGPD"""
        print("üá™üá∫ RAPPORT DE CONFORMIT√â RGPD")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=periode_jours)

        # 1. Acc√®s aux donn√©es personnelles
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as acces_donnees_perso
            FROM audit_log
            WHERE timestamp > ?
              AND table_cible IN ('utilisateurs', 'clients', 'donnees_personnelles')
              AND action = 'SELECT'
            GROUP BY nom_utilisateur
            ORDER BY acces_donnees_perso DESC
        """, (date_debut,))

        print("üìã Acc√®s aux donn√©es personnelles:")
        acces_donnees = cursor.fetchall()
        if acces_donnees:
            for utilisateur, acces in acces_donnees:
                print(f"   ‚Ä¢ {utilisateur}: {acces} consultations")
        else:
            print("   ‚ÑπÔ∏è Aucun acc√®s aux donn√©es personnelles enregistr√©")
        print()

        # 2. Modifications de donn√©es personnelles
        cursor.execute("""
            SELECT nom_utilisateur, action, COUNT(*) as modifications
            FROM audit_log
            WHERE timestamp > ?
              AND table_cible IN ('utilisateurs', 'clients', 'donnees_personnelles')
              AND action IN ('INSERT', 'UPDATE', 'DELETE')
            GROUP BY nom_utilisateur, action
            ORDER BY modifications DESC
        """, (date_debut,))

        print("‚úèÔ∏è Modifications de donn√©es personnelles:")
        for utilisateur, action, count in cursor.fetchall():
            print(f"   ‚Ä¢ {utilisateur} - {action}: {count} fois")
        print()

        # 3. Suppressions (droit √† l'effacement)
        cursor.execute("""
            SELECT COUNT(*) as suppressions_totales,
                   COUNT(DISTINCT enregistrement_id) as enregistrements_supprimes
            FROM audit_log
            WHERE timestamp > ?
              AND action = 'DELETE'
              AND table_cible IN ('utilisateurs', 'clients', 'donnees_personnelles')
        """, (date_debut,))

        suppressions = cursor.fetchone()
        print(f"üóëÔ∏è Suppressions (droit √† l'effacement):")
        print(f"   ‚Ä¢ Total suppressions: {suppressions[0]}")
        print(f"   ‚Ä¢ Enregistrements uniques supprim√©s: {suppressions[1]}")
        print()

        # 4. Violations potentielles
        cursor.execute("""
            SELECT COUNT(*) as violations_potentielles
            FROM audit_log
            WHERE timestamp > ?
              AND statut != 'SUCCESS'
              AND table_cible IN ('utilisateurs', 'clients', 'donnees_personnelles')
        """, (date_debut,))

        violations = cursor.fetchone()[0]
        if violations > 0:
            print(f"‚ö†Ô∏è Violations potentielles d√©tect√©es: {violations}")
            print("   ‚Üí Enqu√™te recommand√©e")
        else:
            print("‚úÖ Aucune violation d√©tect√©e")

        conn.close()

    def rapport_sox(self, periode_jours: int = 90):
        """G√©n√®re un rapport de conformit√© SOX (Sarbanes-Oxley)"""
        print("\nüè¢ RAPPORT DE CONFORMIT√â SOX")
        print("=" * 60)

        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_debut = datetime.now() - timedelta(days=periode_jours)

        # 1. Contr√¥les d'acc√®s aux donn√©es financi√®res
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as acces_financiers
            FROM audit_log
            WHERE timestamp > ?
              AND table_cible IN ('transactions', 'factures', 'comptabilite', 'salaires')
              AND action IN ('SELECT', 'INSERT', 'UPDATE', 'DELETE')
            GROUP BY nom_utilisateur
            ORDER BY acces_financiers DESC
        """, (date_debut,))

        print("üí∞ Acc√®s aux donn√©es financi√®res:")
        for utilisateur, acces in cursor.fetchall():
            print(f"   ‚Ä¢ {utilisateur}: {acces} op√©rations")
        print()

        # 2. S√©paration des t√¢ches (Segregation of Duties)
        cursor.execute("""
            SELECT nom_utilisateur,
                   SUM(CASE WHEN action = 'INSERT' THEN 1 ELSE 0 END) as creations,
                   SUM(CASE WHEN action = 'UPDATE' THEN 1 ELSE 0 END) as modifications,
                   SUM(CASE WHEN action = 'DELETE' THEN 1 ELSE 0 END) as suppressions
            FROM audit_log
            WHERE timestamp > ?
              AND table_cible IN ('transactions', 'factures', 'comptabilite')
            GROUP BY nom_utilisateur
        """, (date_debut,))

        print("üîê Analyse de s√©paration des t√¢ches:")
        violations_separation = []
        for utilisateur, creations, modifications, suppressions in cursor.fetchall():
            total_actions = creations + modifications + suppressions
            if total_actions > 0:
                # V√©rifier si un utilisateur a trop de privil√®ges
                privileges = sum([1 for x in [creations, modifications, suppressions] if x > 0])
                if privileges >= 3 and total_actions > 10:  # Seuils configurables
                    violations_separation.append(utilisateur)

                print(f"   ‚Ä¢ {utilisateur}: C:{creations} M:{modifications} S:{suppressions}")

        if violations_separation:
            print("   ‚ö†Ô∏è Violations potentielles de s√©paration des t√¢ches:")
            for utilisateur in violations_separation:
                print(f"      ‚Üí {utilisateur}")
        else:
            print("   ‚úÖ S√©paration des t√¢ches respect√©e")
        print()

        # 3. Tra√ßabilit√© des modifications critiques
        cursor.execute("""
            SELECT COUNT(*) as modifications_critiques
            FROM audit_log
            WHERE timestamp > ?
              AND table_cible IN ('transactions', 'factures', 'comptabilite')
              AND action IN ('UPDATE', 'DELETE')
              AND anciennes_valeurs IS NOT NULL
        """, (date_debut,))

        modifications_critiques = cursor.fetchone()[0]
        print(f"üìä Tra√ßabilit√© des modifications critiques:")
        print(f"   ‚Ä¢ {modifications_critiques} modifications trac√©es avec d√©tails")

        if modifications_critiques > 0:
            print("   ‚úÖ Tra√ßabilit√© conforme")
        else:
            print("   ‚ö†Ô∏è Aucune modification critique trac√©e")

        # 4. Contr√¥les temporels (modifications en dehors des heures)
        cursor.execute("""
            SELECT nom_utilisateur, COUNT(*) as modifications_hors_heures
            FROM audit_log
            WHERE timestamp > ?
              AND table_cible IN ('transactions', 'factures', 'comptabilite')
              AND action IN ('INSERT', 'UPDATE', 'DELETE')
              AND (CAST(strftime('%H', timestamp) AS INTEGER) < 8
                   OR CAST(strftime('%H', timestamp) AS INTEGER) > 18
                   OR strftime('%w', timestamp) IN ('0', '6'))
            GROUP BY nom_utilisateur
            ORDER BY modifications_hors_heures DESC
        """, (date_debut,))

        print("\n‚è∞ Contr√¥les temporels (modifications hors heures ouvrables):")
        modifications_hors_heures = cursor.fetchall()
        if modifications_hors_heures:
            for utilisateur, count in modifications_hors_heures:
                print(f"   ‚ö†Ô∏è {utilisateur}: {count} modifications hors heures")
        else:
            print("   ‚úÖ Toutes les modifications en heures ouvrables")

        conn.close()

    def generer_rapport_complet(self, format_export: str = 'json'):
        """G√©n√®re un rapport de conformit√© complet exportable"""
        print(f"\nüìÑ G√âN√âRATION RAPPORT COMPLET (format: {format_export})")
        print("=" * 60)

        rapport = {
            'metadata': {
                'date_generation': datetime.now().isoformat(),
                'periode_analyse_jours': 30,
                'base_de_donnees': self.chemin_base
            },
            'conformite': {
                'rgpd': self._analyser_conformite_rgpd(),
                'sox': self._analyser_conformite_sox(),
                'iso27001': self._analyser_conformite_iso27001()
            },
            'recommandations': self._generer_recommandations()
        }

        if format_export == 'json':
            fichier = f"rapport_conformite_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(fichier, 'w', encoding='utf-8') as f:
                json.dump(rapport, f, indent=2, ensure_ascii=False, default=str)
            print(f"‚úÖ Rapport JSON g√©n√©r√©: {fichier}")

        elif format_export == 'html':
            fichier = f"rapport_conformite_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            self._generer_rapport_html(rapport, fichier)
            print(f"‚úÖ Rapport HTML g√©n√©r√©: {fichier}")

        return rapport

    def _analyser_conformite_rgpd(self) -> Dict:
        """Analyse la conformit√© RGPD"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        # V√©rifications RGPD
        date_limite = datetime.now() - timedelta(days=30)

        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > ? AND table_cible IN ('utilisateurs', 'clients')
        """, (date_limite,))
        acces_donnees_perso = cursor.fetchone()[0]

        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > ? AND action = 'DELETE'
              AND table_cible IN ('utilisateurs', 'clients')
        """, (date_limite,))
        suppressions_rgpd = cursor.fetchone()[0]

        conn.close()

        score_conformite = 0
        issues = []

        # Scoring RGPD
        if acces_donnees_perso > 0:
            score_conformite += 25
        else:
            issues.append("Aucun acc√®s aux donn√©es personnelles trac√©")

        if suppressions_rgpd >= 0:  # Au moins 0 (table existe)
            score_conformite += 25

        return {
            'score': score_conformite,
            'max_score': 100,
            'conformite_percentage': (score_conformite / 100) * 100,
            'acces_donnees_personnelles': acces_donnees_perso,
            'suppressions_rgpd': suppressions_rgpd,
            'issues': issues,
            'statut': 'CONFORME' if score_conformite >= 75 else 'NON_CONFORME'
        }

    def _analyser_conformite_sox(self) -> Dict:
        """Analyse la conformit√© SOX"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_limite = datetime.now() - timedelta(days=90)

        # V√©rifications SOX
        cursor.execute("""
            SELECT COUNT(DISTINCT nom_utilisateur) FROM audit_log
            WHERE timestamp > ? AND table_cible IN ('transactions', 'factures')
        """, (date_limite,))
        utilisateurs_financiers = cursor.fetchone()[0]

        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > ? AND table_cible IN ('transactions', 'factures')
              AND action IN ('UPDATE', 'DELETE') AND anciennes_valeurs IS NOT NULL
        """, (date_limite,))
        modifications_tracees = cursor.fetchone()[0]

        conn.close()

        score_sox = 0
        issues = []

        if utilisateurs_financiers > 0:
            score_sox += 40

        if modifications_tracees > 0:
            score_sox += 40
        else:
            issues.append("Modifications financi√®res non trac√©es en d√©tail")

        return {
            'score': score_sox,
            'max_score': 100,
            'conformite_percentage': (score_sox / 100) * 100,
            'utilisateurs_acces_financier': utilisateurs_financiers,
            'modifications_tracees': modifications_tracees,
            'issues': issues,
            'statut': 'CONFORME' if score_sox >= 75 else 'NON_CONFORME'
        }

    def _analyser_conformite_iso27001(self) -> Dict:
        """Analyse la conformit√© ISO 27001"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        date_limite = datetime.now() - timedelta(days=30)

        # V√©rifications ISO 27001
        cursor.execute("""
            SELECT COUNT(*) FROM audit_securite
            WHERE timestamp > ?
        """, (date_limite,))
        evenements_securite = cursor.fetchone()[0]

        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > ? AND statut != 'SUCCESS'
        """, (date_limite,))
        incidents_securite = cursor.fetchone()[0]

        conn.close()

        score_iso = 0
        issues = []

        if evenements_securite > 0:
            score_iso += 50
        else:
            issues.append("Aucun √©v√©nement de s√©curit√© trac√©")

        if incidents_securite == 0:
            score_iso += 30
        elif incidents_securite < 5:
            score_iso += 15
        else:
            issues.append(f"Nombreux incidents de s√©curit√©: {incidents_securite}")

        return {
            'score': score_iso,
            'max_score': 100,
            'conformite_percentage': (score_iso / 100) * 100,
            'evenements_securite': evenements_securite,
            'incidents_securite': incidents_securite,
            'issues': issues,
            'statut': 'CONFORME' if score_iso >= 75 else 'NON_CONFORME'
        }

    def _generer_recommandations(self) -> List[str]:
        """G√©n√®re des recommandations d'am√©lioration"""
        conn = sqlite3.connect(self.chemin_base)
        cursor = conn.cursor()

        recommandations = []

        # V√©rifier si l'audit est complet
        cursor.execute("SELECT COUNT(*) FROM audit_log WHERE timestamp > datetime('now', '-7 days')")
        logs_recents = cursor.fetchone()[0]

        if logs_recents < 100:
            recommandations.append("Augmenter la granularit√© de l'audit - peu d'activit√© enregistr√©e")

        # V√©rifier la r√©tention
        cursor.execute("SELECT MIN(timestamp) FROM audit_log")
        plus_ancien = cursor.fetchone()[0]
        if plus_ancien:
            plus_ancien_date = datetime.fromisoformat(plus_ancien)
            if (datetime.now() - plus_ancien_date).days < 90:
                recommandations.append("Augmenter la p√©riode de r√©tention des logs (minimum 90 jours)")

        # V√©rifier les erreurs
        cursor.execute("""
            SELECT COUNT(*) FROM audit_log
            WHERE timestamp > datetime('now', '-7 days') AND statut != 'SUCCESS'
        """)
        erreurs_recentes = cursor.fetchone()[0]

        if erreurs_recentes > 10:
            recommandations.append("Investiguer et corriger les erreurs fr√©quentes dans les logs")

        conn.close()

        if not recommandations:
            recommandations.append("Syst√®me d'audit fonctionnel - continuer la surveillance")

        return recommandations

    def _generer_rapport_html(self, rapport: Dict, fichier: str):
        """G√©n√®re un rapport HTML lisible"""
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Rapport de Conformit√© SQLite</title>
    <meta charset="utf-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background: #f0f0f0; padding: 20px; border-radius: 5px; }}
        .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #007acc; }}
        .conforme {{ color: green; font-weight: bold; }}
        .non-conforme {{ color: red; font-weight: bold; }}
        .score {{ font-size: 24px; font-weight: bold; }}
        .issue {{ background: #ffe6e6; padding: 5px; margin: 5px 0; border-radius: 3px; }}
        .recommendation {{ background: #e6f3ff; padding: 5px; margin: 5px 0; border-radius: 3px; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üìä Rapport de Conformit√© SQLite</h1>
        <p><strong>G√©n√©r√© le:</strong> {rapport['metadata']['date_generation']}</p>
        <p><strong>Base de donn√©es:</strong> {rapport['metadata']['base_de_donnees']}</p>
    </div>

    <div class="section">
        <h2>üá™üá∫ Conformit√© RGPD</h2>
        <div class="score {'conforme' if rapport['conformite']['rgpd']['statut'] == 'CONFORME' else 'non-conforme'}">
            Score: {rapport['conformite']['rgpd']['score']}/100 ({rapport['conformite']['rgpd']['conformite_percentage']:.1f}%)
        </div>
        <p><strong>Statut:</strong> <span class="{'conforme' if rapport['conformite']['rgpd']['statut'] == 'CONFORME' else 'non-conforme'}">{rapport['conformite']['rgpd']['statut']}</span></p>
        <p>Acc√®s aux donn√©es personnelles: {rapport['conformite']['rgpd']['acces_donnees_personnelles']}</p>
        <p>Suppressions RGPD: {rapport['conformite']['rgpd']['suppressions_rgpd']}</p>
        {"".join([f'<div class="issue">‚ö†Ô∏è {issue}</div>' for issue in rapport['conformite']['rgpd']['issues']])}
    </div>

    <div class="section">
        <h2>üè¢ Conformit√© SOX</h2>
        <div class="score {'conforme' if rapport['conformite']['sox']['statut'] == 'CONFORME' else 'non-conforme'}">
            Score: {rapport['conformite']['sox']['score']}/100 ({rapport['conformite']['sox']['conformite_percentage']:.1f}%)
        </div>
        <p><strong>Statut:</strong> <span class="{'conforme' if rapport['conformite']['sox']['statut'] == 'CONFORME' else 'non-conforme'}">{rapport['conformite']['sox']['statut']}</span></p>
        <p>Utilisateurs avec acc√®s financier: {rapport['conformite']['sox']['utilisateurs_acces_financier']}</p>
        <p>Modifications trac√©es: {rapport['conformite']['sox']['modifications_tracees']}</p>
        {"".join([f'<div class="issue">‚ö†Ô∏è {issue}</div>' for issue in rapport['conformite']['sox']['issues']])}
    </div>

    <div class="section">
        <h2>üîí Conformit√© ISO 27001</h2>
        <div class="score {'conforme' if rapport['conformite']['iso27001']['statut'] == 'CONFORME' else 'non-conforme'}">
            Score: {rapport['conformite']['iso27001']['score']}/100 ({rapport['conformite']['iso27001']['conformite_percentage']:.1f}%)
        </div>
        <p><strong>Statut:</strong> <span class="{'conforme' if rapport['conformite']['iso27001']['statut'] == 'CONFORME' else 'non-conforme'}">{rapport['conformite']['iso27001']['statut']}</span></p>
        <p>√âv√©nements de s√©curit√©: {rapport['conformite']['iso27001']['evenements_securite']}</p>
        <p>Incidents de s√©curit√©: {rapport['conformite']['iso27001']['incidents_securite']}</p>
        {"".join([f'<div class="issue">‚ö†Ô∏è {issue}</div>' for issue in rapport['conformite']['iso27001']['issues']])}
    </div>

    <div class="section">
        <h2>üí° Recommandations</h2>
        {"".join([f'<div class="recommendation">‚Ä¢ {rec}</div>' for rec in rapport['recommandations']])}
    </div>
</body>
</html>
        """

        with open(fichier, 'w', encoding='utf-8') as f:
            f.write(html_content)

# Utilisation des rapports de conformit√©
conformite = ConformiteReglementaire('ma_base.db')

print("=== RAPPORTS DE CONFORMIT√â R√âGLEMENTAIRE ===")
conformite.rapport_rgpd(30)
conformite.rapport_sox(90)

# G√©n√©rer le rapport complet
rapport_complet = conformite.generer_rapport_complet('json')
print(f"üìä Score global moyen: {sum([r['score'] for r in rapport_complet['conformite'].values()]) / 3:.1f}/100")
```

## Conclusion et bonnes pratiques

### R√©capitulatif des concepts essentiels

L'audit et le logging dans SQLite n√©cessitent une approche m√©thodique et bien planifi√©e. Voici les points cl√©s √† retenir :

#### **üîë Principes fondamentaux**

1. **Auditez ce qui compte** : Ne pas tout enregistrer, mais cibler les op√©rations critiques
2. **Pensez performance** : L'audit ne doit pas ralentir l'application
3. **S√©curisez les logs** : Les logs eux-m√™mes contiennent des donn√©es sensibles
4. **Planifiez la r√©tention** : √âquilibrer besoins r√©glementaires et espace disque
5. **Automatisez l'analyse** : Les logs ne servent que s'ils sont analys√©s

#### **üìã Checklist de d√©ploiement**

```
‚òê Tables d'audit cr√©√©es avec index appropri√©s
‚òê Triggers automatiques configur√©s pour les tables critiques
‚òê Syst√®me de rotation et archivage des logs configur√©
‚òê Alertes automatiques en place
‚òê Rapports de conformit√© automatis√©s
‚òê Proc√©dures de maintenance d√©finies
‚òê Formation √©quipe sur l'interpr√©tation des logs
‚òê Tests de r√©cup√©ration des donn√©es d'audit
‚òê Documentation des proc√©dures d'audit
‚òê Validation avec l'√©quipe l√©gale/conformit√©
```

#### **‚ö° Optimisations recommand√©es**

```sql
-- Optimisations de performance pour les tables d'audit
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA cache_size = 10000;

-- Index sp√©cialis√©s pour l'audit
CREATE INDEX idx_audit_user_date ON audit_log(nom_utilisateur, timestamp);
CREATE INDEX idx_audit_table_action ON audit_log(table_cible, action);
CREATE INDEX idx_audit_record ON audit_log(table_cible, enregistrement_id);
```

#### **üö® Alertes critiques √† configurer**

- **√âchecs d'authentification r√©p√©t√©s** (>5 en 15 min)
- **Modifications massives** (>100 enregistrements en 1h)
- **Acc√®s hors heures** aux donn√©es sensibles
- **Erreurs de base de donn√©es** fr√©quentes
- **Tentatives d'injection SQL** d√©tect√©es
- **Modifications de sch√©ma** non autoris√©es

#### **üìä M√©triques KPI √† surveiller**

```python
# M√©triques essentielles √† monitorer
kpi_audit = {
    'volume_logs_quotidien': 'Nombre de logs g√©n√©r√©s par jour',
    'taux_erreur': 'Pourcentage d\'op√©rations en erreur',
    'temps_reponse_moyen': 'Latence moyenne des op√©rations',
    'utilisateurs_actifs': 'Nombre d\'utilisateurs uniques par p√©riode',
    'pic_activite': 'Heures de plus forte activit√©',
    'conformite_score': 'Score de conformit√© r√©glementaire',
    'taille_logs': 'Espace disque utilis√© par les logs',
    'retention_effective': 'Anciennet√© des logs les plus anciens'
}
```

### **üéØ Recommandations par type d'application**

#### **Applications web**
- Logger les sessions utilisateur
- Tracer les modifications via API REST
- Impl√©menter l'audit par adresse IP
- Configurer les alertes de s√©curit√© web

#### **Applications mobiles**
- Audit des synchronisations
- Tra√ßabilit√© des modifications offline
- Gestion des conflits de donn√©es
- Logging des erreurs de connectivit√©

#### **Applications d'entreprise**
- Conformit√© r√©glementaire stricte
- S√©paration des environnements (dev/test/prod)
- Int√©gration avec SIEM d'entreprise
- Rapports automatis√©s pour audits

#### **Applications IoT/embarqu√©es**
- Audit minimal pour pr√©server les ressources
- Compression et rotation fr√©quente des logs
- Transmission s√©curis√©e vers serveurs centraux
- Gestion de la perte de connectivit√©

### **üîÑ Cycle de vie de l'audit**

1. **Planification** : D√©finir les exigences d'audit
2. **Impl√©mentation** : D√©velopper les m√©canismes d'audit
3. **D√©ploiement** : Activer l'audit en production
4. **Surveillance** : Monitor continu des logs
5. **Analyse** : G√©n√©ration de rapports r√©guliers
6. **Optimisation** : Am√©lioration continue du syst√®me
7. **Archivage** : Gestion du cycle de vie des donn√©es

### **üìö Ressources pour aller plus loin**

- **Standards de conformit√©** : GDPR, SOX, ISO 27001, HIPAA
- **Outils de SIEM** : Splunk, ELK Stack, Graylog
- **Frameworks d'audit** : COBIT, NIST Cybersecurity Framework
- **Biblioth√®ques Python** : `logging`, `audit-log`, `python-audit`

L'audit et le logging constituent la fondation de la s√©curit√© et de la conformit√© de votre application SQLite. Un syst√®me bien con√ßu vous permettra non seulement de r√©pondre aux exigences r√©glementaires, mais aussi d'am√©liorer continuellement la s√©curit√© et les performances de votre application.

---

*Cette section compl√®te le chapitre 8.3 sur l'audit et le logging des op√©rations SQLite. La section suivante (8.4) abordera les sauvegardes automatis√©es et les strat√©gies de r√©cup√©ration.*

‚è≠Ô∏è
